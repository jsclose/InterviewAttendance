---
title: "The Interview Attendance Problem"
author: "Jake Close and Peter Kaplan"
date: "11/21/2017"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Context

The data pertains to the recruitment industry in India for the years 2014-2016 and deals with candidate interview attendance for various clients. When candidates don't appear for interviews, valuable time and resources are lost. If HR is able to predict which canidates may not appear, they could save money.

#importing libraries and reading data
```{r}
library(dummies)
library(class)
library(gmodels)
library(ggplot2)
library(dplyr)
library(C50)
interviews <- read.csv("Interview.csv")
```


#data cleaning

It appears the are extra columns read that are completely full of NA's. Lets drop these.


```{r}
interviews <- interviews[, 1:23]
```


Lets rename the variables to make them more readable
```{r}
names <- c("Date", "Client", "Industry", "Location", "Position", "Skillset", "Interview_Type", "ID", "Gender", "Candidate_Loc", "Job_Location", "Venue", "Native_Loc", "Permission", "Hope", "3_hour_call", "Alt_Number", "Resume_Printout", "Clarify_Venue", "Share_Letter", "Expected", "Attendance", "Marital_Status")
colnames(interviews) <- names
```


Next, lets explore which variables may need to be cleaned.


We check the intial structure of the dataset in order to do some data cleaning and exploration
```{r}
str(interviews)
```
From the intial structure, it appears that all of the variables are factor based. Lets explore these factors to make sure that there are no duplicates or NA

It appears that most of the columns have 1 NA. Lets see which if this is the last value?
```{r}
tail(interviews)
interviews <- interviews[1:1232, ]
```

#ID
For Classifation, we should drop Candidate ID since it is unique for each row.
```{r}
interviews <- interviews[, -8]
```


#Predictor Variable Attendance
Lets explore our predictor variable, observed attendance:
Again, we find this is dirty, so lets convert to lowercase first and trim.


```{r}
interviews$Attendance <- trimws(interviews$Attendance)
interviews$Attendance <- tolower(interviews$Attendance)
interviews$Attendance <- as.factor(interviews$Attendance)

round(prop.table(table(interviews$Attendance)) * 100, 1)

```
We find about a 1/3 to 2/3 split of people that have attended.

#Industry
```{r}
levels(interviews$Industry)

levels(interviews$Industry) <- c("BFSI", "Electronics", "IT", "IT", "IT", "Pharmaceuticals", "Telecom")

table(interviews$Industry)

```
It looks like there are three factors with IT in it. Lets combine these factors to one.

```{r}
levels(interviews$Industry)[levels(interviews$Industry) == "IT Products and Services"] <- "IT"
levels(interviews$Industry)[levels(interviews$Industry) == "IT Services"] <- "IT"
levels(interviews$Industry)

barplot(table(interviews$Industry))
```
```{r}
attendenceByIndustry <- interviews %>%
    group_by(Industry, Attendance) %>%
    summarise(count = n())


#% of rides by customer type
plot<-ggplot(data=attendenceByIndustry, aes(x=Industry, y=count, fill = (Attendance)))+
  geom_bar(stat="identity" , position = "dodge")
plot 
```



#Location
```{r}
levels(interviews$Location)

levels(interviews$Location) <- c("Cochin","Bangalore","Chennai", "Chennai", "Chennai", "Chennai", "Delhi","Gurgaon","Gurgaonr","Hyderabad", "Noida")

```
It looks like Chennai is spelt differently for four different factors, lets combine these. Also, Gurgaon is split with an extra r. We can fix this by converting all locations to lower

```{r}
interviews$Location <- tolower(interviews$Location)
levels(interviews$Location)[levels(interviews$Location) == "gurgaonr"] <- "gurgaon"
interviews$Location <- trimws(interviews$Location)
table(interviews$Location)
```

#Position
```{r}
levels(interviews$Position)

```


```{r}
barplot(table(interviews$Position))
```
```{r}
attendenceByPosition <- interviews %>%
    group_by(Position, Attendance) %>%
    summarise(count = n())


#% of rides by customer type
plot<-ggplot(data=attendenceByPosition, aes(x=Position, y=count, fill = (Attendance)))+
  geom_bar(stat="identity" , position = "dodge")
plot 
```




#Gender
```{r}
barplot(table(interviews$Gender))
```
We see that the data is much more male dominated.

```{r}
par(mfrow=c(3,3))
interviews$Hope <- trimws(interviews$Hope)
interviews$Hope <- tolower(interviews$Hope)
interviews$Hope <- as.factor(interviews$Hope)
levels(interviews$Hope)[levels(interviews$Hope) == "na"] <- "unsure"
levels(interviews$Hope)[levels(interviews$Hope) == "cant say"] <- "unsure"
levels(interviews$Hope)[levels(interviews$Hope) == "not sure"] <- "unsure"
barplot(table(interviews$Hope))
title("Hope Distribution")


interviews$Permission <- trimws(interviews$Permission)
interviews$Permission <- tolower(interviews$Permission)
interviews$Permission <- as.factor(interviews$Permission)
levels(interviews$Permission)[levels(interviews$Permission) == "not yet"] <- "no"
levels(interviews$Permission)[levels(interviews$Permission) == "na"] <- "no"
levels(interviews$Permission)[levels(interviews$Permission) == "yet to confirm"] <- "no"
barplot(table(interviews$Permission))
title("Permission Distribution")

interviews$Alt_Number <- trimws(interviews$Alt_Number)
interviews$Alt_Number <- tolower(interviews$Alt_Number)
interviews$Alt_Number <- as.factor(interviews$Alt_Number)
levels(interviews$Alt_Number)[levels(interviews$Alt_Number) == "na"] <- "no"
levels(interviews$Alt_Number)[levels(interviews$Alt_Number) == "no i have only thi number"] <- "no"
barplot(table(interviews$Alt_Number),las=2)
title("Alt Number Distribution")



interviews$Resume_Printout <- trimws(interviews$Resume_Printout)
interviews$Resume_Printout <- tolower(interviews$Resume_Printout)
interviews$Resume_Printout <- as.factor(interviews$Resume_Printout)
levels(interviews$Resume_Printout)[levels(interviews$Resume_Printout) == "no- will take it soon"] <- "yes"
levels(interviews$Resume_Printout)[levels(interviews$Resume_Printout) == "not yet"] <- "no"
levels(interviews$Resume_Printout)[levels(interviews$Resume_Printout) == "na"] <- "no"

barplot(table(interviews$Resume_Printout),las=2)
title("Resume_Printout Distribution")

interviews$Clarify_Venue <- trimws(interviews$Clarify_Venue)
interviews$Clarify_Venue <- tolower(interviews$Clarify_Venue)
interviews$Clarify_Venue <- as.factor(interviews$Clarify_Venue)
levels(interviews$Clarify_Venue)[levels(interviews$Clarify_Venue) == "na"] <- "no"
levels(interviews$Clarify_Venue)[levels(interviews$Clarify_Venue) == "no- i need to check"] <- "no"
barplot(table(interviews$Clarify_Venue),las=2)
title("Clarify_Venue Distribution")


interviews$`3_hour_call` <- trimws(interviews$`3_hour_call`)
interviews$`3_hour_call` <- tolower(interviews$`3_hour_call`)
interviews$`3_hour_call` <- as.factor(interviews$`3_hour_call`)
levels(interviews$`3_hour_call`)[levels(interviews$`3_hour_call`) == "na"] <- "no"
levels(interviews$`3_hour_call`)[levels(interviews$`3_hour_call`) == "no dont"] <- "no"
barplot(table(interviews$`3_hour_call`))
title("3 hour call Distribution")


interviews$Share_Letter <- trimws(interviews$Share_Letter)
interviews$Share_Letter <- tolower(interviews$Share_Letter)
interviews$Share_Letter <- as.factor(interviews$Share_Letter)
levels(interviews$Share_Letter)[levels(interviews$Share_Letter) == "havent checked"] <- "no"
levels(interviews$Share_Letter)[levels(interviews$Share_Letter) == "need to check"] <- "no"
levels(interviews$Share_Letter)[levels(interviews$Share_Letter) == "not sure"] <- "no"
levels(interviews$Share_Letter)[levels(interviews$Share_Letter) == "yet to check"] <- "no"
levels(interviews$Share_Letter)[levels(interviews$Share_Letter) == "not yet"] <- "no"
levels(interviews$Share_Letter)[levels(interviews$Share_Letter) == "na"] <- "no"
barplot(table(interviews$Share_Letter))
title(main = "Share Letter Distribution")


```



## Native Location
Refers to the candidate's hometown.
```{r}
table(interviews$Native_Loc)


# - Cochin- and Delhi/NCR stops the maps api from working, how to remove?

levels(interviews$Native_Loc)[levels(interviews$Native_Loc) == "- Cochin-"] <- "Cochin"
levels(interviews$Native_Loc)[levels(interviews$Native_Loc) == "Delhi /NCR"] <- "Delhi"

interviews$Native_Loc[interviews$Native_Loc == "Delhi /NCR"] <- "NCR"
interviews$Native_Loc[interviews$Native_Loc == "- Cochin-  "] <- "Cochin"

interviews <- interviews[!(interviews$Native_Loc== "Delhi /NCR"),]
interviews <- interviews[!(interviews$Native_Loc== "- Cochin-  "),]


```
The majority of locations are <25, with the major candidate locations coming from Chennai, Hyderbad, and Bangalore.

##Job Location

```{r}

table(interviews$Job_Location)
interviews$Job_Location <- trimws(interviews$Job_Location)
interviews$Job_Location <- tolower(interviews$Job_Location)
levels(interviews$Job_Location) <- c("Cochin","Bangalore","Chennai", "Gurgaonr","Hosur", "Noida", "Visakapatinam")

```

#Distance function

Work-in-progress need to now create a new column in the original table with the distances from this lookup table. 

```{r}
library("gmapsdistance")

distances_lookup_table <- read.csv("distances.csv")

#Only want to make the Google Maps API calls once so this was run then written to csv. 
#Lets loop through and make an API call for each city to find distances
if (FALSE){
  set.api.key("") #Key hidden 
  
  distinct = interviews %>% distinct(Native_Loc) 
  cities = interviews %>% distinct(Job_Location) 
  
  cities <- cities[,colSums(is.na(cities))<nrow(cities)]
  
  cities <- cities[!is.na(cities)]
  distinct <- distinct[is.na(cities)]
  distinct <- distinct[-1]
  
  distinct$"Hosur" <- 0
  distinct$"Bangalore" <- 0
  distinct$"Chennai" <- 0
  distinct$"Guraonr" <- 0
  distinct$"Visakapatinam" <- 0
  distinct$"Cochib" <- 0
  distinct$"Noida" <- 0
               
  for(j in 1:ncol(distinct) -1) {        
    for(i in 1:nrow(distinct)) {
        results <- gmapsdistance(origin = as.character(distinct[i,1]), 
                            destination =as.character(cities[j]),
                            mode = "driving")
        distinct[i,j+1] = results$Distance
    }
  }
  
  write.csv(distinct, 'distances.csv')
}

distances_lookup_table <- distances_lookup_table[-6,]
names(distances_lookup_table)[5] <- "Gurgaon"
interviews$Location[interviews$Location == "Gurgaonr"] <- "Gurgaon"
  
# Function that returns the distance in the lookup table  
lookup <- function(distances_lookup_table, start, end) {
  dist <- distances_lookup_table[tolower(distances_lookup_table$Native_Loc) == as.character(start), as.character(end)]
  
  if (is.null(dist)){
    return (-1)
  } else {
    return(dist)
  }
 
}

# Lets set the distance column in the interveiw section
for(i in 1:nrow(interviews)){  
  val <-lookup(distances_lookup_table, tolower(interviews$Location[i]), sapply((as.character(interviews$Venue[i])),function(x) paste(toupper(substr(x,1,1)),substr(x,2,nchar(x)),sep="")))
  
  interviews$Distance[i] <- val
}
 


```



#Interview Type
There are three different types:
 Walkin drives, Scheduled, and scheduled walkin
```{r}
table(interviews$Interview_Type)
```
It appears the scheduled walkin is described in three ways. Lets combine these.
```{r}
interviews$Interview_Type <- trimws(interviews$Interview_Type)
interviews$Interview_Type <- tolower(interviews$Interview_Type)
interviews$Interview_Type <- as.factor(interviews$Interview_Type)
levels(interviews$Interview_Type)[levels(interviews$Interview_Type) == "sceduled walkin"] <- "scheduled walk in"
levels(interviews$Interview_Type)[levels(interviews$Interview_Type) == "scheduled walkin"] <- "scheduled walk in"
barplot(table((interviews$Interview_Type)))
```

```{r}
attendenceByType <- interviews %>%
    group_by(Interview_Type, Attendance) %>%
    summarise(count = n())


#% of rides by customer type
plot<-ggplot(data=attendenceByType, aes(x=Interview_Type, y=count, fill = (Attendance)))+
  geom_bar(stat="identity" , position = "dodge")
plot 
```



#Expected
Lets clean up expected

```{r}
table(interviews$Expected)
```
Lets convert 10:30 am and 11:00 am to Yes
```{r}
interviews$Expected <- trimws(interviews$Expected)
interviews$Expected <- tolower(interviews$Expected)
interviews$Expected <- as.factor(interviews$Expected)
levels(interviews$Expected)[levels(interviews$Expected) == "10.30 am"] <- "yes"
levels(interviews$Expected)[levels(interviews$Expected) == "11:00 am"] <- "yes"
levels(interviews$Expected)[levels(interviews$Expected) == "NA"] <- "no"

barplot(table((interviews$Expected)))
```
```{r}
attendenceByExpected <- interviews %>%
    group_by(Expected, Attendance) %>%
    summarise(count = n())


#% of rides by customer type
plot<-ggplot(data=attendenceByExpected, aes(x=Expected, y=count, fill = (Attendance)))+
  geom_bar(stat="identity" , position = "dodge")
plot 
```


#Client
```{r}
table(interviews$Client)
```
It looks like we can combine  Hewitt, Aon Hewitt and Aon Hewitt Gurgoan. Also Charted Bank?

```{r}
levels(interviews$Client)[levels(interviews$Client) == "Hewitt"] <- "Aon Hewitt"
levels(interviews$Client)[levels(interviews$Client) == "Aon hewitt Gurgaon"] <- "Aon Hewitt"
levels(interviews$Client)[levels(interviews$Client) == "Standard Chartered Bank Chennai"] <- "Standard Chartered Bank"
```
```{r}
attendenceByClient <- interviews %>%
    group_by(Client, Attendance) %>%
    summarise(count = n())


#% of rides by customer type
plot<-ggplot(data=attendenceByClient, aes(x=Client, y=count, fill = (Attendance)))+
  geom_bar(stat="identity" , position = "dodge")
plot 
```



###Marital Status
```{r}
barplot(table(interviews$Marital_Status))


```
```{r}
attendenceByMarriage <- interviews %>%
    group_by(Marital_Status, Attendance) %>%
    summarise(count = n())


#% of rides by customer type
plot<-ggplot(data=attendenceByMarriage, aes(x=Marital_Status, y=count, fill = (Attendance)))+
  geom_bar(stat="identity" , position = "dodge")
plot 
```

The date variable appears to be in many different formats.
```{r}
table(interviews$Date)
```

#Skillsets
The skillset factor appears to have many different factors with similar names and also some factors that don't appear to be skillsets.
```{r}
table(interviews$Skillset)
```





#Decision Trees
```{r}
#create subset without skill or date
i <- interviews[-1]
i <- i[-5]
i[is.na(i)] <- "no"
colSums(is.na.data.frame(i))


# create a random sample for training and test data
# use set.seed to use the same random number sequence as the tutorial
set.seed(12345)
i_rand <- i[order(runif(1232)), ]

i_train <- i[1:1000, ]
i_test <- i[1001:1232, ]

#Compare the two for similar proportiins, looks good.
prop.table(table(i_train$Attendance))
prop.table(table(i_test$Attendance))

#create mode
interview_model <- C5.0(i_train[-19], i_train$Attendance, trials = 50)


interview_model

# display detailed information about the tree
summary(interview_model)

## Evaluating model performance ----
# create a factor vector of predictions on test data
interview_pred <- predict(interview_model, i_test)

# cross tabulation of predicted versus actual classes
#library(gmodels)
CrossTable(i_test$Attendance, interview_pred,
           prop.chisq = FALSE, prop.c = FALSE, prop.r = FALSE,
           dnn = c('actual Attendance', 'predicted Attendance'))

```
To potentially improve the model, we can include an error matrix. 

```{r}
## Making some mistakes more costly than others
# create a cost matrix
error_cost <- matrix(c(0, 6, 1, 0), nrow = 2)
error_cost

# apply the cost matrix to the tree
interview_cost <- C5.0(i_train[-19], i_train$Attendance,
                          costs = error_cost, trials = 40)
interview_cost_pred <- predict(interview_cost, i_test)

CrossTable(i_test$Attendance, interview_cost_pred,
           prop.chisq = FALSE, prop.c = FALSE, prop.r = FALSE,
           dnn = c('actual attendance', 'predicted attendance'))
```





#SVM
```{r}
# Step 2: Training a model on the data
# begin by training a simple linear SVM
library(kernlab)
attendance_classifier <- ksvm(Attendance ~ ., data = i_train,
                          kernel = "vanilladot")

# look at basic information about the model
attendance_classifier

## Step 3: Evaluating model performance 
# predictions on testing dataset
attendance_predictions <- predict(attendance_classifier, i_test)

head(attendance_predictions)

table(attendance_predictions, i_test$Attendance)
```



KNN
```{r}
i_num <-model.matrix(~ ., data = i)
```





